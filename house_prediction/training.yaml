# PIPELINE DEFINITION
# Name: training
# Inputs:
#    hyperparameters: dict
#    preprocessed_dataset: system.Dataset
# Outputs:
#    metrics: system.Metrics
#    model: system.Model
#    training-metrics: system.Metrics
components:
  comp-training:
    executorLabel: exec-training
    inputDefinitions:
      artifacts:
        preprocessed_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        hyperparameters:
          parameterType: STRUCT
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-training:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - training
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef training(\n    preprocessed_dataset: Input[Dataset],\n    model:\
          \ Output[Model],\n    metrics: Output[Metrics],\n    hyperparameters: dict\n\
          ):\n    \"\"\"Trains the model on the preprocessed dataset.\"\"\"\n    import\
          \ pandas as pd\n    import joblib\n    from sklearn.model_selection import\
          \ train_test_split\n    from sklearn.ensemble import RandomForestRegressor\n\
          \    from sklearn.metrics import mean_squared_error, r2_score\n    import\
          \ logging\n\n    logging.basicConfig(level=logging.INFO)\n\n    # Load preprocessed\
          \ dataset\n    df = pd.read_csv(preprocessed_dataset.path)\n    logging.info(f\"\
          Loaded preprocessed dataset with shape: {df.shape}\")\n\n    # 1. Split\
          \ features and target (assuming 'price' is the target)\n    X = df.drop('price',\
          \ axis=1)\n    y = df['price']\n\n    logging.info(f\"Features shape: {X.shape},\
          \ Target shape: {y.shape}\")\n\n    # 2. Split into train and validation\
          \ sets\n    X_train, X_val, y_train, y_val = train_test_split(\n       \
          \ X, y, test_size=0.2, random_state=hyperparameters.get('random_state',\
          \ 42)\n    )\n\n    logging.info(f\"Training set size: {len(X_train)}, Validation\
          \ set size: {len(X_val)}\")\n\n    # 3. Initialize and train the model\n\
          \    rf_model = RandomForestRegressor(\n        n_estimators=hyperparameters.get('n_estimators',\
          \ 100),\n        max_depth=hyperparameters.get('max_depth', 10),\n     \
          \   random_state=hyperparameters.get('random_state', 42)\n    )\n    rf_model.fit(X_train,\
          \ y_train)\n\n    logging.info(\"Model training complete!\")\n\n    # 4.\
          \ Make predictions\n    y_pred = rf_model.predict(X_val)\n\n    # 5. Calculate\
          \ metrics\n    mse = mean_squared_error(y_val, y_pred)\n    r2 = r2_score(y_val,\
          \ y_pred)\n\n    # Log metrics\n    metrics.log_metric(\"mse\", float(mse))\n\
          \    metrics.log_metric(\"r2_score\", float(r2))\n\n    # 6. Save the model\n\
          \    joblib.dump(rf_model, model.path)\n    logging.info(f\"Model saved\
          \ to: {model.path}\")\n    logging.info(f\"Validation MSE: {mse:.2f}\")\n\
          \    logging.info(f\"Validation R2: {r2:.2f}\")\n\n"
        image: europe-west4-docker.pkg.dev/vertex-ai-484314/vertex-ai-pipeline-thang/training:latest
pipelineInfo:
  name: training
root:
  dag:
    outputs:
      artifacts:
        metrics:
          artifactSelectors:
          - outputArtifactKey: metrics
            producerSubtask: training
        model:
          artifactSelectors:
          - outputArtifactKey: model
            producerSubtask: training
        training-metrics:
          artifactSelectors:
          - outputArtifactKey: metrics
            producerSubtask: training
    tasks:
      training:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-training
        inputs:
          artifacts:
            preprocessed_dataset:
              componentInputArtifact: preprocessed_dataset
          parameters:
            hyperparameters:
              componentInputParameter: hyperparameters
        taskInfo:
          name: training
  inputDefinitions:
    artifacts:
      preprocessed_dataset:
        artifactType:
          schemaTitle: system.Dataset
          schemaVersion: 0.0.1
    parameters:
      hyperparameters:
        parameterType: STRUCT
  outputDefinitions:
    artifacts:
      metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
      model:
        artifactType:
          schemaTitle: system.Model
          schemaVersion: 0.0.1
      training-metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
schemaVersion: 2.1.0
sdkVersion: kfp-2.7.0
